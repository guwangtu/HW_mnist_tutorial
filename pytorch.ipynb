{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "9920512it [05:00, 36253.39it/s]                             Extracting ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[ADownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "\n",
      "  0%|          | 0/28881 [00:05<?, ?it/s]\u001b[A\n",
      "32768it [00:05, 5564.88it/s]                           \n",
      "\n",
      "0it [00:00, ?it/s]\u001b[AExtracting ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n",
      "  0%|          | 0/1648877 [00:05<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:05<00:25, 63487.47it/s]\u001b[A\n",
      "  1%|▏         | 24576/1648877 [00:05<00:32, 50328.26it/s]\u001b[A\n",
      "  2%|▏         | 32768/1648877 [00:06<00:33, 48393.38it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:06<00:38, 41900.47it/s]\u001b[A\n",
      "  3%|▎         | 49152/1648877 [00:06<00:42, 37787.15it/s]\u001b[A\n",
      "  3%|▎         | 57344/1648877 [00:06<00:43, 36320.33it/s]\u001b[A\n",
      "  4%|▍         | 65536/1648877 [00:07<00:41, 37796.94it/s]\u001b[A\n",
      "  4%|▍         | 73728/1648877 [00:07<00:44, 35631.92it/s]\u001b[A\n",
      "  5%|▍         | 81920/1648877 [00:07<00:42, 36774.47it/s]\u001b[A\n",
      "  5%|▌         | 90112/1648877 [00:07<00:43, 35981.66it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:07<00:38, 40035.59it/s]\u001b[A\n",
      "  6%|▋         | 106496/1648877 [00:08<00:39, 39477.10it/s]\u001b[A\n",
      "  7%|▋         | 114688/1648877 [00:08<00:37, 40747.84it/s]\u001b[A\n",
      "  7%|▋         | 122880/1648877 [00:08<00:38, 39630.78it/s]\u001b[A\n",
      "  8%|▊         | 131072/1648877 [00:08<00:42, 35686.03it/s]\u001b[A\n",
      "  8%|▊         | 139264/1648877 [00:09<00:44, 34208.41it/s]\u001b[A\n",
      "  9%|▉         | 147456/1648877 [00:09<00:41, 35938.30it/s]\u001b[A\n",
      "  9%|▉         | 155648/1648877 [00:09<00:42, 35204.69it/s]\u001b[A\n",
      " 10%|▉         | 163840/1648877 [00:09<00:42, 34826.95it/s]\u001b[A\n",
      " 10%|█         | 172032/1648877 [00:10<00:47, 31157.57it/s]\u001b[A\n",
      " 11%|█▏        | 188416/1648877 [00:10<00:41, 35501.10it/s]\u001b[A\n",
      " 12%|█▏        | 196608/1648877 [00:10<00:40, 35584.74it/s]\u001b[A\n",
      " 12%|█▏        | 204800/1648877 [00:10<00:39, 36770.51it/s]\u001b[A\n",
      " 13%|█▎        | 212992/1648877 [00:11<00:44, 32548.21it/s]\u001b[A\n",
      " 14%|█▍        | 229376/1648877 [00:11<00:37, 37669.23it/s]\u001b[A\n",
      " 14%|█▍        | 237568/1648877 [00:11<00:40, 34671.08it/s]\u001b[A\n",
      " 15%|█▍        | 245760/1648877 [00:12<00:47, 29548.05it/s]\u001b[A\n",
      " 15%|█▌        | 253952/1648877 [00:12<00:41, 33506.82it/s]\u001b[A\n",
      " 16%|█▌        | 262144/1648877 [00:12<00:39, 35321.63it/s]\u001b[A\n",
      " 16%|█▋        | 270336/1648877 [00:12<00:32, 42425.33it/s]\u001b[A\n",
      " 17%|█▋        | 278528/1648877 [00:12<00:27, 49050.95it/s]\u001b[A\n",
      " 17%|█▋        | 286720/1648877 [00:12<00:30, 44782.77it/s]\u001b[A\n",
      " 18%|█▊        | 294912/1648877 [00:13<00:30, 44627.12it/s]\u001b[A\n",
      "9920512it [05:20, 36253.39it/s]\n",
      " 19%|█▉        | 311296/1648877 [00:13<00:30, 43498.39it/s]\u001b[A\n",
      " 19%|█▉        | 319488/1648877 [00:13<00:31, 42375.98it/s]\u001b[A\n",
      " 20%|█▉        | 327680/1648877 [00:13<00:34, 38759.37it/s]\u001b[A\n",
      " 20%|██        | 335872/1648877 [00:14<00:34, 38575.36it/s]\u001b[A\n",
      " 21%|██        | 344064/1648877 [00:14<00:34, 37721.46it/s]\u001b[A\n",
      " 21%|██▏       | 352256/1648877 [00:14<00:29, 43538.24it/s]\u001b[A\n",
      " 22%|██▏       | 360448/1648877 [00:14<00:30, 42922.46it/s]\u001b[A\n",
      " 22%|██▏       | 368640/1648877 [00:14<00:34, 36622.65it/s]\u001b[A\n",
      " 23%|██▎       | 376832/1648877 [00:15<00:29, 42497.40it/s]\u001b[A\n",
      " 23%|██▎       | 385024/1648877 [00:15<00:30, 41324.29it/s]\u001b[A\n",
      " 24%|██▍       | 393216/1648877 [00:15<00:31, 40042.74it/s]\u001b[A\n",
      " 24%|██▍       | 401408/1648877 [00:15<00:30, 40250.58it/s]\u001b[A\n",
      " 25%|██▍       | 409600/1648877 [00:15<00:30, 40456.24it/s]\u001b[A\n",
      " 25%|██▌       | 417792/1648877 [00:16<00:37, 33145.69it/s]\u001b[A\n",
      " 26%|██▋       | 434176/1648877 [00:16<00:31, 38253.25it/s]\u001b[A\n",
      " 27%|██▋       | 442368/1648877 [00:16<00:31, 37912.05it/s]\u001b[A\n",
      " 27%|██▋       | 450560/1648877 [00:16<00:30, 38905.38it/s]\u001b[A\n",
      " 28%|██▊       | 458752/1648877 [00:17<00:30, 38945.48it/s]\u001b[A\n",
      " 28%|██▊       | 466944/1648877 [00:17<00:30, 38899.33it/s]\u001b[A\n",
      " 29%|██▉       | 475136/1648877 [00:17<00:30, 38475.29it/s]\u001b[A\n",
      " 29%|██▉       | 483328/1648877 [00:17<00:30, 37696.90it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:18<00:33, 34900.14it/s]\u001b[A\n",
      " 30%|███       | 499712/1648877 [00:18<00:33, 34495.63it/s]\u001b[A\n",
      " 31%|███       | 507904/1648877 [00:18<00:29, 38445.20it/s]\u001b[A\n",
      " 31%|███▏      | 516096/1648877 [00:18<00:30, 37424.48it/s]\u001b[A\n",
      " 32%|███▏      | 524288/1648877 [00:18<00:29, 37927.11it/s]\u001b[A\n",
      " 32%|███▏      | 532480/1648877 [00:19<00:29, 37451.72it/s]\u001b[A\n",
      " 33%|███▎      | 540672/1648877 [00:19<00:29, 37965.76it/s]\u001b[A\n",
      " 33%|███▎      | 548864/1648877 [00:19<00:28, 38016.86it/s]\u001b[A\n",
      " 34%|███▍      | 557056/1648877 [00:19<00:28, 38740.60it/s]\u001b[A\n",
      " 34%|███▍      | 565248/1648877 [00:20<00:29, 36253.28it/s]\u001b[A\n",
      " 35%|███▍      | 573440/1648877 [00:20<00:27, 39786.06it/s]\u001b[A\n",
      " 35%|███▌      | 581632/1648877 [00:20<00:34, 30904.56it/s]\u001b[A\n",
      " 36%|███▌      | 589824/1648877 [00:20<00:28, 37216.58it/s]\u001b[A\n",
      " 36%|███▋      | 598016/1648877 [00:20<00:28, 37342.41it/s]\u001b[A\n",
      " 37%|███▋      | 614400/1648877 [00:21<00:24, 42163.19it/s]\u001b[A\n",
      " 38%|███▊      | 622592/1648877 [00:21<00:24, 42119.77it/s]\u001b[A\n",
      " 38%|███▊      | 630784/1648877 [00:21<00:24, 42307.48it/s]\u001b[A\n",
      " 39%|███▉      | 638976/1648877 [00:21<00:23, 42481.17it/s]\u001b[A\n",
      " 39%|███▉      | 647168/1648877 [00:21<00:23, 42345.37it/s]\u001b[A\n",
      " 40%|███▉      | 655360/1648877 [00:22<00:23, 42423.27it/s]\u001b[A\n",
      " 40%|████      | 663552/1648877 [00:22<00:23, 42413.62it/s]\u001b[A\n",
      " 41%|████      | 671744/1648877 [00:22<00:22, 42535.13it/s]\u001b[A\n",
      " 41%|████      | 679936/1648877 [00:22<00:24, 39067.56it/s]\u001b[A\n",
      " 42%|████▏     | 688128/1648877 [00:22<00:22, 42880.99it/s]\u001b[A\n",
      " 42%|████▏     | 696320/1648877 [00:23<00:21, 43800.80it/s]\u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:23<00:22, 42836.68it/s]\u001b[A\n",
      " 43%|████▎     | 712704/1648877 [00:23<00:22, 42254.38it/s]\u001b[A\n",
      " 44%|████▎     | 720896/1648877 [00:23<00:21, 43546.04it/s]\u001b[A\n",
      " 44%|████▍     | 729088/1648877 [00:23<00:21, 42892.30it/s]\u001b[A\n",
      " 45%|████▍     | 737280/1648877 [00:24<00:21, 43020.16it/s]\u001b[A\n",
      " 45%|████▌     | 745472/1648877 [00:24<00:21, 42504.20it/s]\u001b[A\n",
      " 46%|████▌     | 753664/1648877 [00:24<00:21, 42086.86it/s]\u001b[A\n",
      " 46%|████▌     | 761856/1648877 [00:24<00:23, 37487.09it/s]\u001b[A\n",
      " 47%|████▋     | 770048/1648877 [00:24<00:22, 38943.01it/s]\u001b[A\n",
      " 47%|████▋     | 778240/1648877 [00:25<00:20, 41701.98it/s]\u001b[A\n",
      " 48%|████▊     | 786432/1648877 [00:25<00:18, 45519.98it/s]\u001b[A\n",
      " 48%|████▊     | 794624/1648877 [00:25<00:19, 44322.17it/s]\u001b[A\n",
      " 49%|████▊     | 802816/1648877 [00:25<00:19, 43106.94it/s]\u001b[A\n",
      " 49%|████▉     | 811008/1648877 [00:25<00:22, 36965.57it/s]\u001b[A\n",
      " 50%|█████     | 827392/1648877 [00:26<00:19, 42232.67it/s]\u001b[A\n",
      " 51%|█████     | 835584/1648877 [00:26<00:19, 42142.68it/s]\u001b[A\n",
      " 51%|█████     | 843776/1648877 [00:26<00:18, 42534.37it/s]\u001b[A\n",
      " 52%|█████▏    | 851968/1648877 [00:26<00:19, 41855.93it/s]\u001b[A\n",
      " 52%|█████▏    | 860160/1648877 [00:26<00:19, 40788.05it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:27<00:18, 41195.40it/s]\u001b[A\n",
      " 53%|█████▎    | 876544/1648877 [00:27<00:18, 40754.69it/s]\u001b[A\n",
      " 54%|█████▎    | 884736/1648877 [00:27<00:18, 40222.49it/s]\u001b[A\n",
      " 54%|█████▍    | 892928/1648877 [00:27<00:18, 40143.75it/s]\u001b[A\n",
      " 55%|█████▍    | 901120/1648877 [00:28<00:19, 39291.74it/s]\u001b[A\n",
      " 55%|█████▌    | 909312/1648877 [00:28<00:18, 39151.55it/s]\u001b[A\n",
      " 56%|█████▌    | 917504/1648877 [00:28<00:18, 39947.76it/s]\u001b[A\n",
      " 56%|█████▌    | 925696/1648877 [00:28<00:18, 38751.82it/s]\u001b[A\n",
      " 57%|█████▋    | 933888/1648877 [00:28<00:18, 38954.90it/s]\u001b[A\n",
      " 57%|█████▋    | 942080/1648877 [00:29<00:21, 33404.95it/s]\u001b[A\n",
      " 58%|█████▊    | 950272/1648877 [00:29<00:17, 39782.56it/s]\u001b[A\n",
      " 58%|█████▊    | 958464/1648877 [00:29<00:18, 37742.31it/s]\u001b[A\n",
      " 59%|█████▊    | 966656/1648877 [00:29<00:19, 34248.03it/s]\u001b[A\n",
      " 59%|█████▉    | 974848/1648877 [00:30<00:18, 35969.58it/s]\u001b[A\n",
      " 60%|█████▉    | 983040/1648877 [00:30<00:16, 39213.35it/s]\u001b[A\n",
      " 60%|██████    | 991232/1648877 [00:30<00:16, 38796.63it/s]\u001b[A\n",
      " 61%|██████    | 999424/1648877 [00:30<00:17, 37077.05it/s]\u001b[A\n",
      " 61%|██████    | 1007616/1648877 [00:30<00:17, 37711.30it/s]\u001b[A\n",
      " 62%|██████▏   | 1015808/1648877 [00:31<00:16, 37534.47it/s]\u001b[A\n",
      " 62%|██████▏   | 1024000/1648877 [00:31<00:16, 36990.67it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:31<00:17, 34564.37it/s]\u001b[A\n",
      " 63%|██████▎   | 1040384/1648877 [00:31<00:16, 37675.15it/s]\u001b[A\n",
      " 64%|██████▎   | 1048576/1648877 [00:32<00:16, 37014.29it/s]\u001b[A\n",
      " 64%|██████▍   | 1056768/1648877 [00:32<00:15, 37148.09it/s]\u001b[A\n",
      " 65%|██████▍   | 1064960/1648877 [00:32<00:16, 34744.92it/s]\u001b[A\n",
      " 65%|██████▌   | 1073152/1648877 [00:32<00:15, 37492.72it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:32<00:15, 36699.56it/s]\u001b[A\n",
      " 66%|██████▌   | 1089536/1648877 [00:33<00:15, 37122.07it/s]\u001b[A\n",
      " 67%|██████▋   | 1097728/1648877 [00:33<00:14, 36833.72it/s]\u001b[A\n",
      " 67%|██████▋   | 1105920/1648877 [00:33<00:14, 36489.50it/s]\u001b[A\n",
      " 68%|██████▊   | 1114112/1648877 [00:33<00:14, 36159.60it/s]\u001b[A\n",
      " 68%|██████▊   | 1122304/1648877 [00:34<00:14, 35749.42it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:34<00:18, 28623.68it/s]\u001b[A\n",
      " 70%|██████▉   | 1146880/1648877 [00:34<00:14, 34117.57it/s]\u001b[A\n",
      " 70%|███████   | 1155072/1648877 [00:34<00:13, 36397.55it/s]\u001b[A\n",
      " 71%|███████   | 1163264/1648877 [00:35<00:13, 36568.56it/s]\u001b[A\n",
      " 71%|███████   | 1171456/1648877 [00:35<00:13, 36702.83it/s]\u001b[A\n",
      " 72%|███████▏  | 1179648/1648877 [00:35<00:13, 36068.90it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:35<00:12, 36681.86it/s]\u001b[A\n",
      " 73%|███████▎  | 1196032/1648877 [00:36<00:12, 35109.42it/s]\u001b[A\n",
      " 73%|███████▎  | 1204224/1648877 [00:36<00:12, 36438.44it/s]\u001b[A\n",
      " 74%|███████▎  | 1212416/1648877 [00:36<00:11, 37179.77it/s]\u001b[A\n",
      " 74%|███████▍  | 1220608/1648877 [00:36<00:11, 36775.17it/s]\u001b[A\n",
      " 75%|███████▍  | 1228800/1648877 [00:36<00:11, 35705.03it/s]\u001b[A\n",
      " 75%|███████▌  | 1236992/1648877 [00:37<00:11, 35564.87it/s]\u001b[A\n",
      " 76%|███████▌  | 1245184/1648877 [00:37<00:11, 34965.78it/s]\u001b[A\n",
      " 76%|███████▌  | 1253376/1648877 [00:37<00:11, 34633.17it/s]\u001b[A\n",
      " 77%|███████▋  | 1261568/1648877 [00:37<00:11, 34350.68it/s]\u001b[A\n",
      " 77%|███████▋  | 1269760/1648877 [00:38<00:11, 33104.76it/s]\u001b[A\n",
      " 78%|███████▊  | 1277952/1648877 [00:38<00:10, 34816.10it/s]\u001b[A\n",
      " 78%|███████▊  | 1286144/1648877 [00:38<00:13, 26256.12it/s]\u001b[A\n",
      " 78%|███████▊  | 1294336/1648877 [00:38<00:10, 32829.43it/s]\u001b[A\n",
      " 79%|███████▉  | 1302528/1648877 [00:39<00:09, 38073.32it/s]\u001b[A\n",
      " 79%|███████▉  | 1310720/1648877 [00:39<00:09, 37201.25it/s]\u001b[A\n",
      " 80%|███████▉  | 1318912/1648877 [00:39<00:09, 35774.74it/s]\u001b[A\n",
      " 80%|████████  | 1327104/1648877 [00:39<00:09, 35546.22it/s]\u001b[A\n",
      " 81%|████████  | 1335296/1648877 [00:40<00:08, 34931.30it/s]\u001b[A\n",
      " 81%|████████▏ | 1343488/1648877 [00:40<00:08, 34778.24it/s]\u001b[A\n",
      " 82%|████████▏ | 1351680/1648877 [00:40<00:09, 31843.91it/s]\u001b[A\n",
      " 82%|████████▏ | 1359872/1648877 [00:40<00:09, 30974.77it/s]\u001b[A\n",
      " 83%|████████▎ | 1368064/1648877 [00:41<00:07, 36703.26it/s]\u001b[A\n",
      " 83%|████████▎ | 1376256/1648877 [00:41<00:07, 35790.51it/s]\u001b[A\n",
      " 84%|████████▍ | 1384448/1648877 [00:41<00:07, 35231.86it/s]\u001b[A\n",
      " 84%|████████▍ | 1392640/1648877 [00:41<00:07, 34902.66it/s]\u001b[A\n",
      " 85%|████████▍ | 1400832/1648877 [00:42<00:07, 34185.34it/s]\u001b[A\n",
      " 85%|████████▌ | 1409024/1648877 [00:42<00:06, 34623.73it/s]\u001b[A\n",
      " 86%|████████▌ | 1417216/1648877 [00:42<00:06, 33840.12it/s]\u001b[A\n",
      " 86%|████████▋ | 1425408/1648877 [00:42<00:08, 26600.86it/s]\u001b[A\n",
      " 87%|████████▋ | 1433600/1648877 [00:43<00:07, 29660.97it/s]\u001b[A\n",
      " 87%|████████▋ | 1441792/1648877 [00:43<00:07, 28337.47it/s]\u001b[A\n",
      " 88%|████████▊ | 1458176/1648877 [00:43<00:05, 35142.88it/s]\u001b[A\n",
      " 89%|████████▉ | 1466368/1648877 [00:43<00:05, 34870.31it/s]\u001b[A\n",
      " 89%|████████▉ | 1474560/1648877 [00:44<00:05, 34018.40it/s]\u001b[A\n",
      " 90%|████████▉ | 1482752/1648877 [00:44<00:04, 34051.55it/s]\u001b[A\n",
      " 90%|█████████ | 1490944/1648877 [00:44<00:04, 34523.51it/s]\u001b[A\n",
      " 91%|█████████ | 1499136/1648877 [00:44<00:04, 34169.47it/s]\u001b[A\n",
      " 91%|█████████▏| 1507328/1648877 [00:45<00:04, 34140.18it/s]\u001b[A\n",
      " 92%|█████████▏| 1515520/1648877 [00:45<00:03, 33965.33it/s]\u001b[A\n",
      " 92%|█████████▏| 1523712/1648877 [00:45<00:03, 33758.56it/s]\u001b[A\n",
      " 93%|█████████▎| 1531904/1648877 [00:45<00:03, 34153.87it/s]\u001b[A\n",
      " 93%|█████████▎| 1540096/1648877 [00:46<00:03, 34331.43it/s]\u001b[A\n",
      " 94%|█████████▍| 1548288/1648877 [00:46<00:02, 33928.53it/s]\u001b[A\n",
      " 94%|█████████▍| 1556480/1648877 [00:46<00:02, 34415.07it/s]\u001b[A\n",
      " 95%|█████████▍| 1564672/1648877 [00:46<00:02, 33968.72it/s]\u001b[A\n",
      " 95%|█████████▌| 1572864/1648877 [00:47<00:02, 34303.84it/s]\u001b[A\n",
      " 96%|█████████▌| 1581056/1648877 [00:47<00:01, 34206.37it/s]\u001b[A\n",
      " 96%|█████████▋| 1589248/1648877 [00:47<00:01, 34138.60it/s]\u001b[A\n",
      " 97%|█████████▋| 1597440/1648877 [00:47<00:01, 34143.33it/s]\u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:48<00:01, 33561.81it/s]\u001b[A\n",
      " 98%|█████████▊| 1613824/1648877 [00:48<00:01, 34306.24it/s]\u001b[A\n",
      " 98%|█████████▊| 1622016/1648877 [00:48<00:00, 34119.49it/s]\u001b[A\n",
      " 99%|█████████▉| 1630208/1648877 [00:48<00:00, 34344.75it/s]\u001b[A\n",
      " 99%|█████████▉| 1638400/1648877 [00:49<00:00, 31219.23it/s]\u001b[A\n",
      "100%|█████████▉| 1646592/1648877 [00:49<00:00, 27551.00it/s]\u001b[A\n",
      "1654784it [00:49, 28862.00it/s]                             \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[AExtracting ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:05<?, ?it/s]\u001b[A\u001b[AC:\\Users\\gzfox\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "Extracting ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "# TODO:define model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),  # Para: 150\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # Para: 2400\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=64, kernel_size=4, stride=1),  # Para: 2400\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64, out_features=16),  # Para: 30720\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=10),  # Para: 840\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    \n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1\n",
      "Train Accuracy: 98.21%\n",
      "Test Accuracy: 98.20%\n",
      "\n",
      "Epoch 2\n",
      "Train Accuracy: 98.43%\n",
      "Test Accuracy: 98.33%\n",
      "\n",
      "Epoch 3\n",
      "Train Accuracy: 98.50%\n",
      "Test Accuracy: 98.25%\n",
      "\n",
      "Epoch 4\n",
      "Train Accuracy: 98.63%\n",
      "Test Accuracy: 98.51%\n",
      "\n",
      "Epoch 5\n",
      "Train Accuracy: 98.61%\n",
      "Test Accuracy: 98.44%\n",
      "\n",
      "Epoch 6\n",
      "Train Accuracy: 98.76%\n",
      "Test Accuracy: 98.44%\n",
      "\n",
      "Epoch 7\n",
      "Train Accuracy: 98.89%\n",
      "Test Accuracy: 98.42%\n",
      "\n",
      "Epoch 8\n",
      "Train Accuracy: 98.83%\n",
      "Test Accuracy: 98.52%\n",
      "\n",
      "Epoch 9\n",
      "Train Accuracy: 98.97%\n",
      "Test Accuracy: 98.53%\n",
      "\n",
      "Epoch 10\n",
      "Train Accuracy: 99.03%\n",
      "Test Accuracy: 98.47%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_count = 0\n",
    "    train_correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        # TODO:forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        predicts = model.forward(images)\n",
    "        loss_batch = criterion(predicts, labels)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        for (predict, label) in zip(predicts.argmax(dim=1), labels):\n",
    "            train_count += 1\n",
    "            train_correct += (predict == label)\n",
    "    \n",
    "    test_count = 0\n",
    "    test_correct = 0\n",
    "    for images, labels in test_loader:\n",
    "        predicts = model.forward(images)\n",
    "        for (predict, label) in zip(predicts.argmax(dim=1), labels):\n",
    "            # print(predict, label)\n",
    "            test_count += 1\n",
    "            test_correct += (predict == label)\n",
    "\n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    print('Epoch %d' % (epoch + 1))\n",
    "    print('Train Accuracy: %.2f%%' % (train_correct.cpu().numpy() / train_count * 100))\n",
    "    print('Test Accuracy: %.2f%%' % (test_correct.cpu().numpy() / test_count * 100))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd001a87ff6733c416d09f5eac0a50a4a908b985a470771f42a6d71c80298923cc0",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}